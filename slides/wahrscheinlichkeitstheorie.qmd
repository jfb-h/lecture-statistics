---
title: "Einführung in die Statistik"
subtitle: "Statistische Modelle"
author: Dr. Jakob Hoffmann, Economic Geography Group
lightbox: true
execute:
    cache: true
    keep-ipynb: false
    keep-md: false
filters:
    - parse-latex
format:
    revealjs:
        css: custom.css
        controls: true
        slide-number: true
---

```{r}
#| cache: false

library(rlang)
library(dplyr)
library(tidyr)
library(readr)
library(lubridate)
library(stringr)
library(forcats)
library(ggplot2)
library(ggthemes)
library(ggridges)
library(viridis)
library(patchwork)
library(srvyr)
library(posterior)

theme_set(theme_tufte(base_family="Arial"))

theme_update(
  axis.title.x = element_text(hjust = 0.99),
  axis.title.y = element_text(hjust = 0.99),
  plot.title = element_text(face = "bold"),
  plot.caption = element_text(face="italic"),
  strip.text.x = element_text(hjust = 0.01, face = "bold"),
  strip.text.y = element_text(vjust = 0.01, face = "bold"),
  legend.position = "top",
  legend.justification.top = "left"
)

```

## Scheinkorrelationen

![](https://www.tylervigen.com/spurious/correlation/image/2794_popularity-of-the-first-name-margarita_correlates-with_motor-vehicle-thefts-in-indiana.svg){width=900}

## Scheinkorrelationen

![](https://www.tylervigen.com/spurious/correlation/image/2052_gmo-use-in-corn-grown-in-minnesota_correlates-with_pirate-attacks-globally.svg){width=900}

## Scheinkorrelationen
![](https://www.tylervigen.com/spurious/correlation/image/5905_frozen-yogurt-consumption_correlates-with_violent-crime-rates.svg){width=900}
<!-- <iframe width="780" height="500" src="https://www.tylervigen.com/spurious/correlation/5905_frozen-yogurt-consumption_correlates-with_violent-crime-rates" title="Survey preview"> </iframe> -->


# Statistische Modelle


## Statistische Modellierung {.smaller}

Statistische Modellierung umfasst (1) die Spezifikation eines mathematische Modells des DGP, (2) das Lernen von unbekannten Variablen (Parametern), (3) das Überprüfen des Modells, und (4) das Testen von Hypothesen oder das Erstellen von Prognosen.

![](images/statmodels.png){width=1000}


## [①]{style="color: #46b1e1"} Modellkonstruktion

<hr>

**Datengenerierender Prozess**: Wiederholter Münzwurf

  - Faktoren: Eigenschaften der Münze, Wurftechnik, chaotischer physikalischer Prozess

<hr>

**Modell des DGP**: Binomialverteilung

  - Zufallsprozess mit $\textrm{P}(K) = \theta$ und $\textrm{P}(Z) = 1 - \theta$
  - Annahmen: Unabhängige Würfe, kein Einfluss von Wurftechnik, $\theta$ über Würfe konstant


## [①]{style="color: #46b1e1"} Modellstruktur

Ein statistisches Modell kombiniert beobachtete Variablen ([*Daten*]{style="color: orange"}) und unbeobachtete Variablen ([*Parameter*]{style="color: cornflowerblue"}) in einem mathemat. Modell, das bestimmte *Annahmen* verkörpert:

$$
\color{orange}{\textrm{# Kopf}} \sim \textrm{Binomial}(\color{orange}{n}, \color{cornflowerblue}{\theta})
$$

> Wir modellieren die Anzahl Würfe mit Ergebnis 'Kopf' aus insgesamt $n$ Würfen durch eine Binomialverteilung mit unbekanntem Parameter $\theta$ (sprich: Theta). Die Tilde $a \sim b$ liest sich als '$a$ *folgt Verteilung* $b$'.


## [②]{style="color: #47D45A"} Statistische Inferenz

- Das Ziel statistischer Inferenz ist, unbekannte Variablen in einem statistischen Modell (welches den DGP repräsentiert) auf Basis von Beobachtungen des DGP zu schätzen.
- Je mehr Evidenz (d.h. Beobachtungen / Daten) wir haben, desto mehr reduzieren wir die Unsicherheit über die unbekannten Variablen in unserem Modell.
- Im Falle des Münzwurfs interessieren wir uns für den Paramter $\theta$, welcher (unter bestimmten Annahmen) die Fairness der Münze repräsentiert.

## [②]{style="color: #47D45A"} Statistische Inferenz

<video src="images/coinflip.mp4" width="1000" controls autoplay loop muted>
</video>



## [③]{style="color: #F2AA84"} Überprüfung durch Simulation

Entsprechen die Modellvorhersagen den beobachteten Daten?


```{r}
set.seed(123)
dat_coin = tibble(n = 50, zahl = 29, kopf = n - zahl)
fit_coin = stan_glm(cbind(zahl, kopf) ~ 1,
  family=binomial(), data = dat_coin, refresh=0)

pred = predicted_rvars(fit_coin, dat_coin)

pred |> ggplot(aes(xdist = .prediction)) +
  stat_slab(fill="grey70", slab_color="black") +
  geom_vline(xintercept=dat_coin$zahl, linewidth=1.5, color="tomato") +
  annotate("text", x=29.5, y=0.97, label="Beobachtet: #Zahl = 29", color="tomato", size=6, hjust=0) +
  labs(
    x = "# Zahl in 50 Würfen",
    y = "# Simulationen (normalisiert)"
  )

```


## [④]{style="color: #D86ECC"} Ist die Münze fair?

Gegeben der Ergebnisse der 50 beobachteten Münzwürfe hält das Modell Werte für $\theta$ im Bereich 0.3 bis 0.55 für plausibel.

![](images/coinflip.png)

Damit ist nicht auszuschließen, dass die Münze fair ist ($\theta=0.5$), allerdings besteht auch die Möglichkeit eines (geringfügigen) Bias.

## Brexit und Bildungsabschluss


```{r}
library(rstanarm)
library(posterior)
library(tidybayes)
library(ggdist)

bes = readr::read_csv("data/BES.csv")
bes$education = factor(
  bes$education,
  levels = 1:5,
  labels = c(
    "Keine Qualifikation",
    "Realschulabschluss",
    "Abitur",
    "Bachelor",
    "Master"
  )
)

dat = bes |>
  summarize(n=n(), .by = c(vote, education)) |>
  mutate(total = sum(n), .by=education) |> drop_na() |>
  filter(vote %in% c("stay", "leave"))

dat_wide = dat |> pivot_wider(names_from=vote, values_from=n)

fit = stan_glmer(
  cbind(stay, leave) ~ -1 + (1|education),
  family=binomial(), data = dat_wide, refresh=0)
```

```{r, fig.width=11, fig.height=6}
p1 = ggplot(dat, aes(x = vote, y = n, fill = education)) +
  geom_col() +
  facet_wrap(~fct_rev(education), ncol=1, scales="free_y") +
  scale_fill_tableau() +
  labs(x=NULL, y="Häufigkeit") +
  theme(legend.position = "none")

p2 = epred_rvars(fit, dat_wide) |>
  ggplot(aes(y = 1, xdist = .epred, color=education)) +
  stat_pointinterval(.width=0.99) +
  geom_vline(xintercept=0.5, linetype = "dashed") +
  facet_wrap(~fct_rev(education), ncol=1, scales="free_y") +
  # xlim(0, 1) +
  labs(
    x = "θ", y = NULL,
  ) +
  scale_color_tableau() +
  theme(
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    strip.text.y = element_blank(),
    strip.text.x = element_blank()
  )

p3 = predicted_rvars(fit, dat_wide) |>
  # mutate(share = .prediction / total) |>
  ggplot(aes(xdist = .prediction, fill=education)) +
  stat_slab(normalize="panels") +
  geom_vline(dat=dat_wide, aes(xintercept=stay), color = "black") +
  facet_wrap(~fct_rev(education), ncol=1, scales="free_x") +
  scale_fill_tableau() +
  labs(x = "# stay", y="# Simulationen") +
  theme(
    legend.position = "none",
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    strip.text.y = element_blank(),
    strip.text.x = element_blank()
  )

(p1 | p2 | p3) +
  plot_layout(widths = c(0.2, 0.6, 0.2)) +
  plot_annotation(
    tag_levels = "A",
    tag_prefix = "(",
    tag_suffix = ")",
    title = "Zustimmung zum Brexit und Bildungsabschluss",
    subtitle = "Umfrageergebnisse (A), geschätzte Wahrscheinlichket, den Brexit abzulehnen (B) und Modellsimulationen (C).\nDas eingesetzte Modell ist # stayₑ ∼ Binomial(θₑ, nₑ),wobei e den Bildungsstand indiziert.",
    caption = "Datenquelle: BES Survey"
  )
```


## Zwei Quellen von Unsicherheit

- **Aleatorische Unsicherheit** beschreibt systemische Unsicherheit, die nicht durch mehr Beobachtungen aber evtl. durch ein besseres Modell reduziert werden kann (z.B. begrenzte Vorhersagekraft von Wohnungsgröße als einzigem Prädiktor für Mietpreise).

- **Epistemische Unsicherheit** beschreibt Unsicherheit, die aus der begrenzten Verfügbarkeit von Informationen resultiert, und kann durch mehr/bessere Beobachtungen reduziert werden (z.B. Stichprobengröße, Messfehler).


# Wahrscheinlichkeit
Quantifizierung von Unsicherheit

## Wahrscheinlichkeit {.smaller}

::::: columns
::: {.column width="45%"}
![](images/verteilung.png)
:::
::: {.column width="55%"}

- Eine *Wahrscheinlichkeitsverteilung* verteilt eine auf 1 normierte Quantität über die möglichen Resultate eines Zufallsprozesses.

- Die W'keit eines Ereignisses ist eine Zahl zwischen 0 (unmöglich) und 1 (garantiert).

- **Frequentistische Interpretation:** W'keit ist die relative Häufigkeit in einem unendlich wiederholten Experiment (z.B. Münzwurf).

- **Bayesianische Interpretation:** W'keit ist ein konsistentes Maß für 'Grad der Plausibilität' (z.B. W'keit, dass Bayern gegen Donezk gewinnt).

:::
:::::

## Der Ergebnisraum
![](images/prob-1.png)

## Ereignisse
![](images/prob-2.png)

## Wahrscheinlichkeit
![](images/prob-3.png)

## Wahrscheinlichkeit
![](images/prob-4.png)

## Wahrscheinlichkeit
![](images/prob-5.png)

## Wahrscheinlichkeit
![](images/prob-6.png)

## Multiplikationsregel
![](images/prob-7.png)

## Multiplikationsregel
![](images/prob-8.png)

## Multiplikationsregel
![](images/prob-9.png)

## Zufallsvariablen

Eine *Zufallsvariable* $X(E)$ ordnet jedem Ergebnis $E$ im Ergebnisraum eines Zufallsprozesses eine Zahl zu.

Für das Beispiel des Münzwurfs:

$$
X(E) = \begin{cases}
  0, & \text{wenn } E = \textrm{Kopf} \\
  1, & \text{wenn } E = \textrm{Zahl}
\end{cases}
$$

Die Zahlen haben nicht immer eine inheränte Bedeutung. Beim Münzwurf könnte die Zuordung auch andersherum erfolgen.

Statt mit $X(E)$ wird eine Zufallsvariable häufig auch einfach mit $X$ bezeichnet.


## Bernoulliverteilung

Eine der bekanntesten W'keitsverteilungen ist die *Bernoulli-verteilung* für eine binäre Zufallsvariable $X$ (Wertebereich 0 oder 1) mit Wahrscheinlichkeitsfunktion:

$$
\textrm{Ber}(X = \color{cornflowerblue}{x} | \color{orange}{\theta}) =
\color{orange}{\theta}^\color{cornflowerblue}{x} (1 - \color{orange}{\theta})^{1-\color{cornflowerblue}{x}} \\
$$

zum Beispiel mit $\theta = 0{,}7$:

$$
\begin{align}
\textrm{Ber}(X = \color{cornflowerblue}{1} | \color{orange}{0{,}7}) &=
\color{orange}{0{,}7}^\color{cornflowerblue}{1} (1 - \color{orange}{0{,}7})^{1-\color{cornflowerblue}{1}} = 0{,}7 \\
\textrm{Ber}(X = \color{cornflowerblue}{0} | \color{orange}{0{,}7}) &=
\color{orange}{0{,}7}^\color{cornflowerblue}{0} (1 - \color{orange}{0{,}7})^{1-\color{cornflowerblue}{0}} = 1 - 0{,}7
\end{align}
$$

## Binomialverteilung

Die *Binomialverteilung* modelliert das Ergebnis einer Reihe von $n$ unabhängigen Bernoulli-Experimenten und hat für eine Zufallsvariable $X$ mit Wertebereich 0 bis $n$ die W'keitsfunktion:

$$
\textrm{Bin}(X = \color{cornflowerblue}{x} | n, \color{orange}{\theta}) =
\binom{n}{x}
\color{orange}{\theta}^\color{cornflowerblue}{x} (1 - \color{orange}{\theta})^{n-\color{cornflowerblue}{x}} \\
$$

Der Faktor $\binom{n}{x}$ ist der *Binomialkoeffizient* und zählt, wie viele unterschiedliche Möglichkeiten es gibt, aus $n$ Elementen genau $x$ auszuwählen.


## Binomialverteilung

```{r, fig.width=11, fig.height=6}
d = tibble(x=0:20,  y=dbinom(x, 20, 0.3))

d |> ggplot(aes(x=x, y=0, xend=x, yend=y)) +
  geom_hline(yintercept=0) +
  geom_point(aes(y=y), color="tomato", size=3) +
  geom_segment(color="tomato") +
  # X = 7
  geom_point(dat=filter(d, x==7), aes(y=y), color="cornflowerblue", size=3.5) +
  geom_segment(dat=filter(d, x==7), color="cornflowerblue", linewidth=1.2) +
  labs(x="x", y="P(X=x)", title = "Bin(X = x | 20, 0.3)")
```

::: {.fragment .smaller}
<div class="annotation" style="color: cornflowerblue; top: 170px; left: 410px">
  $\tiny P(X=7|20, 0{,}3) = {7 \choose 20} 0{,}3^7 (1 -0{,}3)^{20-7} = 0.164$
</div>
:::


## Binomialverteilung

```{r, fig.width=11, fig.height=6}
d = rbind(
  tibble(x=0:20, p="Bin(X=x | n= 20, θ = 0.3)",  y=dbinom(x, 20, 0.3)),
  tibble(x=0:20, p="Bin(X=x | n= 20, θ = 0.5)",  y=dbinom(x, 20, 0.5)),
  tibble(x=0:20, p="Bin(X=x | n= 20, θ = 0.7)",  y=dbinom(x, 20, 0.7))
)

d |> ggplot(aes(x=x, y=0, xend=x, yend=y, color=as.factor(p))) +
  geom_hline(yintercept=0) +
  geom_point(aes(y=y), size=3) +
  geom_segment() +
  facet_wrap(~as.factor(p), ncol=1) +
  theme(legend.position="none") +
  labs(x="x", y="P(X=x)")
```

## Zufällige Realisierungen

::::: columns
::: {.column width="50%"}
![Generieren von zufälligen Werten aus einer Binomialverteilung mit n = 20 und θ = 0.3 mit der Programmiersprache Julia.](images/julia-rand.png)
:::
::: {.column width="50%"}
Mit einem Computer können Realisierungen von Zufalls-prozessen generiert werden, die bestimmten Verteilungen (wie der Binomialverteilung) entsprechen.

```{r, fig.width=5, fig.height=2}
d = tibble(x=rbinom(1000, 20, 0.3))

d |> summarize(n=n(), .by=x) |>
ggplot(aes(x=x, y=n)) +
  geom_col(fill="grey70", color="grey20") +
  labs(x="x", y="Häufigkeit", subtitle="1 000 Realisierungen aus X ~ Binom(20, 0.3)")

```
:::
:::::

# Statistische Inferenz
Schätzen unbekannter Parameter

## Statistische Modellierung {.smaller}

Statistische Modellierung umfasst (1) die Spezifikation eines mathematische Modells des DGP, (2) das Lernen von unbekannten Variablen (Parametern), (3) das Überprüfen des Modells, und (4) das Testen von Hypothesen oder das Erstellen von Prognosen.

![](images/statmodels.png){width=1000}

::: {.fragment .fade-in-then-out}
<div class="rectangle" style="top: 200px; left: 170px; width: 280px; height: 100px;"></div>
:::

::: {.fragment}
<div class="rectangle" style="top: 530px; left: 530px; width: 340px; height: 100px;"></div>
:::


## Statistische Inferenz

Wir suchen für unbekannte Parameter $\theta$ Werte, die im Angesicht der beobachteten Daten $D$ plausibel sind. Wir suchen nach der *bedingten Verteilung* von $\theta$ *gegeben* $D$:

$$p(\theta|D)$$

:::{.fragment}
Im Falle eines wiederholten Münzwurfes mit $D = 90K, 10Z$ und $P(K)=\theta$, was ist plausibler: $\theta = 0.2$ oder $\theta = 0.8$?

$$p(\theta = 0.2 |D) \quad \textrm{vs.} \quad p(\theta = 0.8 |D)$$
:::

## Gemeinsame Wahrscheinlichkeit

Die gemeinsame W'keit $P(A, B)$ zweier Zufallsereignisse ist die W'keit, dass sowohl $A$ als auch $B$ eintreten.

Beispiel: W'keit, Geographie zu studieren und Grün zu wählen:

|                | Grün | Andere | Gesamt |
|----------------|------|--------|--------|
| Geograph       | 0.10 | 0.05   | 0.15   |
| nicht Geograph | 0.30 | 0.55   | 0.85   |
| Gesamt         | 0.40 | 0.60   | 1.00   |

Reihen-/Spaltensummen sind *Randverteilungen* von $A$ und $B$.


## Bedingte Wahrscheinlichkeit

Die *bedingte W'keit* von $A$ gegeben $B$ ist definiert als die gemeinsame W'keit von $A$ und $B$ normiert durch die W'keit von $B$:

$$
P(A|B) = \frac{P(A, B)}{P(B)}
$$

<!-- Konditionieren auf bereits erlangte Information ist ein zentrales Instrument zur systematischen Integration von Evidenz in unsere Modelle. -->

:::{.fragment}
Zusätzlich gilt das *Gesetz totaler W'keit*:
$$
P(A) = P(A|B)P(B) + P(A|B^c)P(B^c)
$$

wobei $B^c$, das Ereignis bezeichnet, dass $B$ *nicht* eintritt.
:::


## Bedingte Wahrscheinlichkeit

Was ist die W'keit, dass eine Geographin Grün wählt?

|                | Grün | Andere | Gesamt |
|----------------|------|--------|--------|
| [Geograph]{style="color: tomato"}       | [0.10]{style="color: tomato"} | [0.05]{style="color: tomato"} | [0.15]{style="color: tomato"} |
| nicht Geograph | 0.30 | 0.55   | 0.85   |
| Gesamt         | 0.40 | 0.60   | 1.00   |

$$
P(\textrm{Grün} | \textrm{Geo}) =
\frac{P(\textrm{Grün}, \textrm{Geo})}{P(\textrm{Geo})} =
\frac{0.10}{0.15} = \frac{2}{3}
$$



## Unabhängigkeit

Zwei Ereignisse $A$ und $B$ sind formell *unabhängig*, wenn konditionieren auf $B$ an unseren Informationen über $A$ nichts ändert, d.h. wenn:

$$
P(A|B) = P(A)
$$

(Un)abhängigkeit ist *symmetrisch*, d.h. $P(A|B) = P(A)$ impliziert auch $P(B|A) = P(B)$.


## Bayes' Regel

Eine Erweiterung bedingter W'keit ist *Bayes' Regel*, die das Kernstück *Bayesianischer Inferenz* bildet:

$$
P(A | B) = \frac{P(A,B)}{P(B)} = \frac{P(B | A) P(A)}{P(B)}
$$

Bayes' Regel folgt direkt durch Umstellen der Definition bedingter W'keit:

$$
P(A,B) = P(A|B)P(B) = P(B|A) P(A) 
$$

## P(Krankheit | Test positiv)

$K$ ist das Ereignis, an einer seltenen Krankheit erkrankt zu sein und $T$ das Ereignis, positiv auf die Krankheit getestet zu werden. Wir interessieren uns für $P(K|T)$: die W'keit erkrankt zu sein, gegeben dass ein positives Testergebnis vorliegt.

<hr>

**Vorhandene Informationen:**

- Inzidenz der Krankheit: $P(K) = 0{,}01$
- Genauigkeit des Tests: $P(T|K) = P(T^c|K^c) = 0{,}95$

## P(Krankheit | Test positiv)

Anwenden von Bayes' Regel ergibt:

$$
\begin{align}
P(K | T) &= \frac{P(T | K) P(K)}{P(T)} \\[8pt]
&= \frac{P(T | K) P(K)}{P(T|K)P(K) + P(T|K^c)P(K^c)} \\[8pt]
&= \frac{0{,}95 \times 0{,}01}{0{,}95 \times 0{,}01 + 0{,}05 \times 0{,}99} = 0{,}16
\end{align}
$$


## Bayesianische Inferenz

Bayes' Regel kann für statistische Inferenz unbekannter Parameter $\theta$ im Angesicht von Daten $D$ eingesetzt werden:

$$
\color{tomato}{p(\theta | D)} = \frac{\color{orange}{p(D | \theta)} \color{cornflowerblue}{p(\theta)}}{p(D)}
$$

- $\color{tomato}{p(\theta | D)}$ ist die *a-posteriori-Verteilung* von $\theta$
- $\color{cornflowerblue}{p(\theta)}$ ist die *a-priori-Verteilung* von $\theta$
- $\color{orange}{p(D | \theta)}$ ist die *Likelihood* (das Modell des DGP)
- $p(D)$ : ist ein Normierungsfaktor

## Bayesianische Inferenz

Die Kurve im Bild rechts zeigt die *a-posteriori-Verteilung*  $\color{tomato}{p(\theta | \textrm{K} = 21)}$ des unbekannten Parameters $\theta$ nach 50 beobachteten Münzwürfen mit 21 mal $K$:

![](images/coinflip.png)

Die eingesetzte Likelihood $\color{orange}{p(K | \theta)} = \textrm{Bin}(K|n, \theta)$ ist die schon besprochene Binomialverteilung als Modell des DGP.

## Bayesianisches Updating

- Bayesianische Inferenz kann verstanden werden als ein systematisches *Updaten* der *a-priori-Verteilung* $\color{cornflowerblue}{p(\theta)}$ durch das Konditionieren auf beobachtete Daten $D$.

- Die *a-priori-Verteilung* selbst hängt nicht von den Daten ab, sondern verkörpert die 'subjektive' Einschätzung der Analystin vor Durchführung der Untersuchung.

- Die *a-priori-Verteilung* kann eingesetzt werden um Vorwissen der Forschenden einzubeziehen und das Modell auf plausible Werte für $\theta$ zu beschränken.



## Prüfungsfragen

- Was ist ein Nachteil der frequentistischen Definition von Wahrscheinlichkeit?
- Berechnen Sie die bedingte W'keit auf Basis der untentstehenden Tabelle für folgende Ereignisse.
- Was ist das Ziel statistischer Inferenz?
- Sie Befragen 1000 Personen dazu, ob sie planen, bei der nächsten Bundestagswahl zu wählen. Was könnte ein geeignetes Modell für den Datengenerierenden Prozess sein? Welche Annahmen verkörpert das Modell?


